---
phase: 2.1-position-polling
plan: 02
type: execute
depends_on: ["2.1-01"]
files_modified: [src/v6/data/position_streamer.py, src/v6/data/test_position_streamer.py]
domain: ib-async-api
inserted: true
urgency: critical
---

<objective>
Redesign IBPositionStreamer to use hybrid approach: stream active strategy contracts, queue non-essential contracts.

**Purpose:** Conserve IB streaming slots by streaming only active contracts (real-time updates) while queueing non-essential contracts for batch processing (0 slots consumed).

**Output:** Working IBPositionStreamer with hybrid logic that checks StrategyRegistry to decide stream vs queue.

**Key Pattern:** Conditional routing - if `registry.is_active(conid)` then stream, else queue.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/2-position-synchronization/STREAMING_SLOTS_ISSUE.md
@.planning/phases/2-position-synchronization/2-01-SUMMARY.md
@.planning/phases/2.1-position-polling/2.1-OVERVIEW.md
@.planning/phases/2.1-position-polling/2.1-01-SUMMARY.md
@src/v6/data/position_streamer.py
@src/v6/data/strategy_registry.py
@src/v6/data/position_queue.py

**Hybrid Logic:**
```
For each position update:
  if registry.is_active(conid):
    â†’ Stream via reqMktData() (real-time, consume slot)
    â†’ Notify handlers immediately
  else:
    â†’ Queue via PositionQueue.insert() (no slot consumed)
    â†’ Process later by QueueWorker (batch)
```

**Streaming Active Contracts:**
- Use `ib.reqMktData(contract, "", "", False)` for real-time updates
- Subscribe to `updatePortfolioEvent` for immediate notifications
- Only active strategy contracts (Iron Condor legs, etc.)
- Worth the slot cost for real-time updates

**Queueing Non-Essential:**
- Use `PositionQueue.insert(conid, symbol, priority=2)`
- Processed later by QueueWorker (5-second intervals, batch of 50)
- 0 streaming slots consumed
- Suitable for analysis/history data

**Tech Stack:**
- ib_async (reqMktData for streaming)
- StrategyRegistry (is_active check)
- PositionQueue (insert non-essential)
- PositionUpdateHandler (notify for streamed updates)

**Established Patterns:**
- Handler registration (already implemented)
- Singleton pattern (already implemented)
- Async lifecycle (already implemented)

**Constraining Decisions:**
- **Stream only active contracts:** Check `registry.is_active(conid)` first
- **Queue non-essential:** All other contracts go to queue
- **Handler notification only for streamed:** Queued updates don't trigger handlers (processed by QueueWorker)
- **Backward compatible:** DeltaLakePositionWriter still works (receives streamed updates)

</context>

<tasks>

<task type="auto">
  <name>Task 1: Redesign IBPositionStreamer with hybrid logic</name>
  <files>src/v6/data/position_streamer.py</files>
  <action>
    Redesign `src/v6/data/position_streamer.py` to use hybrid approach:

    **Key changes:**
    1. Add StrategyRegistry and PositionQueue dependencies
    2. In `start()` method: fetch positions from IB using `reqPositionsAsync()`
    3. For each position: check `registry.is_active(conid)`
    4. If active: subscribe to `reqMktData()` for streaming
    5. If not active: insert into queue via `queue.insert()`
    6. Remove old polling loop (no longer needed)

    ```python
    """
    IB Position Streaming Module (Hybrid: Stream + Queue)

    This module provides hybrid position synchronization from Interactive Brokers:
    - Active strategy contracts: STREAM (real-time updates via reqMktData)
    - Non-essential contracts: QUEUE (batch processing, 0 slots consumed)

    Key patterns:
    - Hybrid approach: stream active, queue non-essential
    - Singleton pattern to respect IB's 100-connection limit
    - Handler registration for streamed position updates
    """

    import asyncio
    from dataclasses import dataclass
    from datetime import datetime
    from typing import List, Optional, Protocol, runtime_checkable

    from loguru import logger
    from ib_async import IB

    from v6.utils.ib_connection import IBConnectionManager
    from v6.data.strategy_registry import StrategyRegistry
    from v6.data.position_queue import PositionQueue

    @dataclass(slots=True)
    class PositionUpdate:
        """Position update from IB streaming."""
        conid: int
        symbol: str
        right: str
        position: float
        market_price: float
        market_value: float
        average_cost: float
        unrealized_pnl: float
        timestamp: datetime

    @runtime_checkable
    class PositionUpdateHandler(Protocol):
        """Protocol for position update handlers."""

        async def on_position_update(self, update: PositionUpdate) -> None:
            """Handle position update."""
            ...

    class IBPositionStreamer:
        """
        Manages IB position synchronization with hybrid approach.

        **Hybrid Architecture:**
        - Active contracts â†’ STREAM (reqMktData, real-time, consume slots)
        - Non-essential contracts â†’ QUEUE (batch processing, 0 slots)

        **Decision Logic:**
        Checks StrategyRegistry.is_active(conid) to determine stream vs queue.

        **Singleton Pattern:**
        Enforces single IB connection instance to respect 100-connection limit.
        """

        _instance: Optional['IBPositionStreamer'] = None

        def __new__(cls):
            if cls._instance is None:
                cls._instance = super().__new__(cls)
            return cls._instance

        def __init__(
            self,
            registry: Optional[StrategyRegistry] = None,
            queue: Optional[PositionQueue] = None
        ):
            """
            Initialize streamer.

            Args:
                registry: StrategyRegistry for checking active contracts
                queue: PositionQueue for queuing non-essential contracts
            """
            self._connection = None
            self._handlers: List[PositionUpdateHandler] = []
            self._registry = registry or StrategyRegistry()
            self._queue = queue or PositionQueue()
            self._is_running = False
            self._streamed_contracts: set[int] = set()  # Track actively streamed contracts

        def register_handler(self, handler: PositionUpdateHandler) -> None:
            """
            Register a handler to receive position updates.

            Handlers are called ONLY for streamed positions (active contracts).
            Queued positions are processed by QueueWorker (no handler notification).

            Args:
                handler: Handler to register
            """
            if handler not in self._handlers:
                self._handlers.append(handler)
                logger.debug(f"Registered handler: {handler.__class__.__name__}")

        async def start(self) -> None:
            """
            Start hybrid position synchronization.

            1. Initialize registry and queue
            2. Get IB connection
            3. Fetch all positions via reqPositionsAsync()
            4. For each position: stream if active, queue if not
            5. Subscribe to updatePortfolioEvent for streamed contracts
            """
            if self._is_running:
                logger.warning("IBPositionStreamer already running")
                return

            logger.info("Starting hybrid position synchronization...")

            # Initialize registry and queue
            await self._registry.initialize()
            await self._queue.initialize()

            # Get IB connection
            from v6.utils.ib_connection import IBConnectionManager
            conn_manager = IBConnectionManager()
            self._connection = await conn_manager.get_connection()

            if not self._connection or not self._connection.is_connected:
                raise ConnectionError("IB not connected")

            ib = self._connection.ib

            # Fetch all positions
            positions = await ib.reqPositionsAsync()
            logger.info(f"Fetched {len(positions)} positions from IB")

            # Hybrid routing: stream active, queue non-essential
            streamed_count = 0
            queued_count = 0

            for item in positions:
                # Only process option positions with non-zero quantity
                if not hasattr(item.contract, 'secType') or item.contract.secType != 'OPT':
                    continue

                if item.position == 0:
                    continue

                conid = item.contract.conId
                symbol = item.contract.symbol

                # Check if contract is in active strategy
                if self._registry.is_active(conid):
                    # STREAM: Subscribe to market data for real-time updates
                    await self._stream_contract(conid, item.contract)
                    streamed_count += 1
                else:
                    # QUEUE: Insert into queue for batch processing
                    await self._queue.insert(conid=conid, symbol=symbol, priority=2)
                    queued_count += 1

            # Subscribe to portfolio updates for streamed contracts
            ib.updatePortfolioEvent += self._on_position_update

            self._is_running = True

            logger.info(
                f"âœ“ Started hybrid position sync: "
                f"{streamed_count} streamed (active), "
                f"{queued_count} queued (non-essential)"
            )

        async def stop(self) -> None:
            """Stop hybrid position synchronization."""
            if not self._is_running:
                return

            self._is_running = False

            if self._connection and self._connection.is_connected:
                # Unsubscribe from portfolio updates
                ib = self._connection.ib
                ib.updatePortfolioEvent -= self._on_position_update

                # Cancel market data subscriptions
                for conid in self._streamed_contracts:
                    try:
                        ib.cancelMktData(conid)
                    except Exception as e:
                        logger.warning(f"Failed to cancel market data for {conid}: {e}")

                self._streamed_contracts.clear()

            logger.info("âœ“ Stopped hybrid position synchronization")

        async def _stream_contract(self, conid: int, contract) -> None:
            """
            Stream market data for active contract.

            Args:
                conid: IB contract ID
                contract: IB Contract object
            """
            try:
                ib = self._connection.ib

                # Subscribe to market data (snapshot=False for streaming)
                ib.reqMktData(
                    contract,
                    "",  # genericTickList (empty for basic data)
                    "",  # snapshot (False = streaming)
                    False  # snapshot
                )

                self._streamed_contracts.add(conid)
                logger.debug(f"âœ“ Streaming contract {conid} ({contract.symbol})")

            except Exception as e:
                logger.error(f"Failed to stream contract {conid}: {e}")

        async def _on_position_update(self, item) -> None:
            """
            Handle portfolio update event (streamed contracts only).

            Called by IB when position changes for streamed contracts.
            Creates PositionUpdate and notifies all handlers.

            Args:
                item: IB PortfolioItem object
            """
            try:
                # Only process option positions
                if not hasattr(item.contract, 'secType') or item.contract.secType != 'OPT':
                    return

                if item.position == 0:
                    return

                # Create PositionUpdate
                update = PositionUpdate(
                    conid=item.contract.conId,
                    symbol=item.contract.symbol,
                    right=item.contract.right,
                    position=item.position,
                    market_price=item.marketPrice,
                    market_value=item.marketValue,
                    average_cost=item.averageCost,
                    unrealized_pnl=item.unrealizedPNL,
                    timestamp=datetime.now()
                )

                # Notify all handlers asynchronously
                for handler in self._handlers:
                    asyncio.create_task(handler.on_position_update(update))

            except Exception as e:
                logger.error(f"Error handling position update: {e}")
    ```

    **CRITICAL:**
    - Hybrid logic: `if registry.is_active(conid)` then stream else queue
    - Active contracts: `reqMktData()` for streaming
    - Non-active contracts: `queue.insert()` for batch processing
    - Handlers notified ONLY for streamed positions
    - Singleton pattern preserved
  </action>
  <verify>
    Run `python -m py_compile src/v6/data/position_streamer.py` - should compile without errors
  </verify>
  <done>
    - IBPositionStreamer redesigned with hybrid logic
    - Checks StrategyRegistry.is_active(conid) for stream vs queue decision
    - Active contracts: reqMktData() for streaming
    - Non-active contracts: queue.insert() for batch processing
    - Handlers notified only for streamed positions
    - Code compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Update integration test for hybrid approach</name>
  <files>src/v6/data/test_position_streamer.py</files>
  <action>
    Update `src/v6/data/test_position_streamer.py` to test hybrid approach:

    ```python
    """
    Integration test for hybrid position synchronization.

    Tests IBPositionStreamer with hybrid approach:
    - Active contracts: streamed (real-time)
    - Non-essential contracts: queued (batch processing)
    """

    import asyncio
    from loguru import logger

    from v6.data.position_streamer import IBPositionStreamer, PositionUpdateHandler, PositionUpdate
    from v6.data.strategy_registry import StrategyRegistry
    from v6.data.position_queue import PositionQueue

    class TestHandler(PositionUpdateHandler):
        """Test handler that logs position updates (streamed only)."""

        def __init__(self):
            self.updates_received = []

        async def on_position_update(self, update: PositionUpdate) -> None:
            logger.info(f"ðŸ“¡ STREAMED UPDATE: {update.symbol} {update.right} (conid: {update.conid}, pos: {update.position})")
            self.updates_received.append(update)

    async def main():
        """Test hybrid position synchronization."""
        logger.info("Testing hybrid position synchronization...")

        # Create registry and queue
        registry = StrategyRegistry(delta_lake_path="data/lake/test_active_strategies")
        queue = PositionQueue(delta_lake_path="data/lake/test_position_queue")

        # Initialize
        await registry.initialize()
        await queue.initialize()

        # Add one active contract (should be streamed)
        await registry.add_active(
            conid=999999,
            symbol="TEST",
            right="CALL",
            strike=450.0,
            expiry="20260220",
            strategy_id=1
        )
        logger.info("âœ“ Added active contract 999999 (should be streamed)")

        # Create streamer with registry and queue
        streamer = IBPositionStreamer(registry=registry, queue=queue)

        # Create handler to catch streamed updates
        handler = TestHandler()
        streamer.register_handler(handler)

        try:
            # Start hybrid sync
            await streamer.start()
            logger.info("âœ“ Hybrid position sync started")

            # Wait for updates
            await asyncio.sleep(5)

            # Stop
            await streamer.stop()
            logger.info("âœ“ Hybrid position sync stopped")

            # Verify results
            logger.info(f"\n=== Results ===")
            logger.info(f"Streamed updates received: {len(handler.updates_received)}")

            # Check queue
            queued_items = await queue.get_batch(priority=2, limit=100)
            logger.info(f"Queued items (non-essential): {len(queued_items)}")

            logger.info("\nâœ“ Test complete")

        except Exception as e:
            logger.error(f"Test failed: {e}")
            logger.info("Note: This test requires IB Gateway/TWS to be running")

    if __name__ == "__main__":
        asyncio.run(main())
    ```

    **Note:** Test verifies that:
    - Active contracts trigger handler notifications (streamed)
    - Non-active contracts end up in queue (queued)
  </action>
  <verify>
    Run `python -m py_compile src/v6/data/test_position_streamer.py` - should compile without errors
  </verify>
  <done>
    - Integration test updated for hybrid approach
    - Tests streaming of active contracts
    - Tests queuing of non-essential contracts
    - Code compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify DeltaLakePositionWriter still works</name>
  <files>src/v6/data/delta_persistence.py</files>
  <action>
    Verify DeltaLakePositionWriter compatibility:

    **Check:** DeltaLakePositionWriter implements PositionUpdateHandler and receives updates via `on_position_update()`.

    **Verification:**
    1. Read delta_persistence.py to confirm it implements PositionUpdateHandler
    2. Confirm `async def on_position_update(self, update: PositionUpdate)` method exists
    3. No changes needed (already compatible with hybrid approach)

    **Reasoning:**
    - DeltaLakePositionWriter registers as handler with IBPositionStreamer
    - It receives ONLY streamed position updates (active contracts)
    - Queued positions are processed by QueueWorker (not DeltaLakePositionWriter)
    - This is correct: we don't need to persist queued positions to Delta Lake immediately
    - QueueWorker will persist them during batch processing

    **Expected:** DeltaLakePositionWriter works without any changes.
  </action>
  <verify>
    Run `python -m py_compile src/v6/data/delta_persistence.py` - should compile without errors
  </verify>
  <done>
    - Confirmed DeltaLakePositionWriter implements PositionUpdateHandler
    - No changes needed (backward compatible)
    - Code compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 4: Run integration test</name>
  <files>src/v6/data/test_position_streamer.py</files>
  <action>
    Run integration test to verify hybrid approach works:

    ```bash
    rm -rf data/lake/test_active_strategies data/lake/test_position_queue
    PYTHONPATH=/home/bigballs/project/bot/v6/src python src/v6/data/test_position_streamer.py
    ```

    **Expected output:**
    ```
    Testing hybrid position synchronization...
    âœ“ Added active contract 999999 (should be streamed)
    âœ“ Hybrid position sync started
    ðŸ“¡ STREAMED UPDATE: TEST CALL (conid: 999999, pos: X)
    âœ“ Hybrid position sync stopped

    === Results ===
    Streamed updates received: 1+
    Queued items (non-essential): 0+

    âœ“ Test complete
    ```

    **Note:** If IB not running, test should gracefully handle connection error.
  </action>
  <verify>
    Test runs without errors (may fail if IB not running, but should show clear error)
  </verify>
  <done>
    - Integration test executed successfully
    - Active contracts streamed (handler notifications received)
    - Non-essential contracts queued (items in queue table)
    - Hybrid logic working correctly
  </done>
</task>

<task type="auto">
  <name>Task 5: Update documentation</name>
  <files>.planning/phases/2-position-synchronization/STREAMING_SLOTS_ISSUE.md</files>
  <action>
    Update STREAMING_SLOTS_ISSUE.md to document hybrid resolution:

    Add to "Resolution" section:

    ```markdown
    ## Resolution (2026-01-26)

    **Selected Approach:** Hybrid (Stream Active, Queue Non-Essential)

    **Implementation:**
    1. **StrategyRegistry**: Tracks which contracts are in active strategies
    2. **PositionQueue**: Delta Lake backed queue for batch processing
    3. **IBPositionStreamer**: Hybrid logic
       - If `registry.is_active(conid)` â†’ Stream via reqMktData()
       - Else â†’ Queue via queue.insert()
    4. **QueueWorker**: Background daemon processes queue (5s intervals, batch of 50)

    **Slot Conservation:**
    - Active contracts: Streamed (real-time, consume slots, worth the cost)
    - Non-essential contracts: Queued (0 slots, batch processed every 5s)
    - Result: ~10 slots for active strategies, scales to thousands of contracts

    **Backward Compatibility:**
    - DeltaLakePositionWriter: Works without changes (receives streamed updates)
    - PositionReconciler: Works without changes (uses reqPositionsAsync)
    - Handler pattern: Preserved (only for streamed updates)

    **Phase 2 Status:** FIXED - Ready for Phase 3
    ```
  </action>
  <verify>
    Documentation updated consistently
  </verify>
  <done>
    - STREAMING_SLOTS_ISSUE.md updated with hybrid resolution
    - Documents StrategyRegistry, PositionQueue, IBPositionStreamer redesign
    - Explains slot conservation benefits
    - Documents backward compatibility
  </done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `python -m py_compile src/v6/data/position_streamer.py` succeeds without errors
- [ ] `python -m py_compile src/v6/data/test_position_streamer.py` succeeds without errors
- [ ] IBPositionStreamer checks `registry.is_active(conid)`
- [ ] Active contracts: `reqMktData()` for streaming
- [ ] Non-essential contracts: `queue.insert()` for batch processing
- [ ] Handlers notified only for streamed positions
- [ ] DeltaLakePositionWriter still works (no changes needed)
- [ ] Integration test demonstrates hybrid approach
- [ ] Documentation updated (STREAMING_SLOTS_ISSUE.md)
- [ ] ruff linter passes with no errors
</verification>

<success_criteria>

- IBPositionStreamer redesigned with hybrid logic
- Checks StrategyRegistry.is_active(conid) for stream vs queue decision
- Active contracts: reqMktData() for streaming (real-time updates)
- Non-essential contracts: queue.insert() for batch processing (0 slots)
- Handlers notified only for streamed positions
- DeltaLakePositionWriter compatible (no changes needed)
- Integration test verifies hybrid routing
- All verification checks pass
- No errors or warnings introduced

</success_criteria>

<output>
After completion, create `.planning/phases/2.1-position-polling/2.1-02-SUMMARY.md`:

# Phase 2.1 Plan 2: IBPositionStreamer Hybrid Redesign Summary

**Redesigned IBPositionStreamer to use hybrid approach: stream active strategy contracts, queue non-essential contracts.**

## Accomplishments

- Redesigned IBPositionStreamer with hybrid logic (stream + queue)
- Checks StrategyRegistry.is_active(conid) for routing decision
- Active contracts: reqMktData() for real-time streaming
- Non-essential contracts: PositionQueue.insert() for batch processing
- Handlers notified only for streamed positions (not queued)
- DeltaLakePositionWriter compatible (no changes needed)

## Files Created/Modified

- `src/v6/data/position_streamer.py` - Redesigned with hybrid logic
- `src/v6/data/test_position_streamer.py` - Updated integration test
- `.planning/phases/2-position-synchronization/STREAMING_SLOTS_ISSUE.md` - Updated resolution

## Decisions Made

- **Hybrid routing:** `if registry.is_active(conid)` then stream else queue
- **Stream active:** reqMktData() for real-time updates (worth slot cost)
- **Queue non-essential:** PositionQueue.insert() for batch processing (0 slots)
- **Handler notification:** Only for streamed positions (queued processed by QueueWorker)
- **Backward compatible:** DeltaLakePositionWriter works without changes

## Slot Conservation

**Before (pure streaming):**
- All positions streamed = 100+ slots
- Hits 100-slot limit at ~100 contracts

**After (hybrid):**
- Active contracts streamed = ~10 slots (fixed)
- Non-essential queued = 0 slots
- Scales to thousands of contracts

## Next Step

Ready for 2.1-03-PLAN.md (Implement QueueWorker Background Daemon)

The hybrid routing is in place:
- IBPositionStreamer decides stream vs queue based on StrategyRegistry
- Active contracts get real-time streaming
- Non-essential contracts go to queue
- QueueWorker will process queue (next plan)

Next: Implement QueueWorker to process queued position updates in batches.

---

**Plan:** 2.1-02-PLAN.md
**Tasks completed:** 5/5
**Deviations encountered:** none
**Commits:** X (X feature commits)
**Status:** COMPLETE
</output>
